{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "comparative-killing",
   "metadata": {},
   "source": [
    "# feature selection & modelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ruled-mouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import featuretools as ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "homeless-center",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.5\n",
      "1.19.2\n",
      "0.23.1\n"
     ]
    }
   ],
   "source": [
    "print(pd.__version__)\n",
    "print(np.__version__)\n",
    "print(ft.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "drawn-difficulty",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/billy/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3050: DtypeWarning: Columns (4) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "df_target_merged = pd.read_csv('./dataset/target_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "streaming-hampton",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_feature = pd.read_csv('./dataset/user_feature_total_remove_highcorr.csv')\n",
    "df_merchant_feature = pd.read_csv('./dataset/merchant_feature_total_remove_highcorr.csv')\n",
    "df_coupon_feature = pd.read_csv('./dataset/coupon_feature_total_remove_highcorr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "blind-twins",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_feature = df_user_feature.add_prefix('user_')\n",
    "df_merchant_feature = df_merchant_feature.add_prefix('merchant_')\n",
    "df_coupon_feature = df_coupon_feature.add_prefix('coupon_')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggregate-execution",
   "metadata": {},
   "source": [
    "## feature seletion \n",
    "To reduce modelling time and avoid the curse of dimensionality, feature selection is necessary for our project.\n",
    "\n",
    "Traditional Methods of feature selection:\n",
    "\n",
    "1. remove features with high missing rate \n",
    "2. remove features with singal value \n",
    "3. remove high correlated features \n",
    "4. univariate statistical test based \n",
    "5. model based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "falling-contractor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# user feature 73\n",
      "# merchant feature 60\n",
      "# coupon feature 39\n"
     ]
    }
   ],
   "source": [
    "print('# user feature {}'.format(df_user_feature.shape[1]-2))\n",
    "print('# merchant feature {}'.format(df_merchant_feature.shape[1]-2))\n",
    "print('# coupon feature {}'.format(df_coupon_feature.shape[1]-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "absent-exchange",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Merchant_id</th>\n",
       "      <th>Coupon_id</th>\n",
       "      <th>Date_received</th>\n",
       "      <th>Date</th>\n",
       "      <th>datediff</th>\n",
       "      <th>target</th>\n",
       "      <th>Month_received</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1439408</td>\n",
       "      <td>4663</td>\n",
       "      <td>11002.0</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>2016-02-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>2016-03-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-03-01</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>2016-06-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-06-01</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>2016-05-16</td>\n",
       "      <td>2016-06-13</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053277</th>\n",
       "      <td>212662</td>\n",
       "      <td>3021</td>\n",
       "      <td>3739.0</td>\n",
       "      <td>2016-05-04</td>\n",
       "      <td>2016-05-08</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053278</th>\n",
       "      <td>212662</td>\n",
       "      <td>2934</td>\n",
       "      <td>5686.0</td>\n",
       "      <td>2016-03-21</td>\n",
       "      <td>2016-03-22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-03-01</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053279</th>\n",
       "      <td>212662</td>\n",
       "      <td>3021</td>\n",
       "      <td>3739.0</td>\n",
       "      <td>2016-05-08</td>\n",
       "      <td>2016-06-02</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053280</th>\n",
       "      <td>752472</td>\n",
       "      <td>7113</td>\n",
       "      <td>1633.0</td>\n",
       "      <td>2016-06-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-06-01</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053281</th>\n",
       "      <td>752472</td>\n",
       "      <td>3621</td>\n",
       "      <td>2705.0</td>\n",
       "      <td>2016-05-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1053282 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         User_id  Merchant_id  Coupon_id Date_received        Date  datediff  \\\n",
       "0        1439408         4663    11002.0    2016-05-28         NaN       NaN   \n",
       "1        1439408         2632     8591.0    2016-02-17         NaN       NaN   \n",
       "2        1439408         2632     1078.0    2016-03-19         NaN       NaN   \n",
       "3        1439408         2632     8591.0    2016-06-13         NaN       NaN   \n",
       "4        1439408         2632     8591.0    2016-05-16  2016-06-13      28.0   \n",
       "...          ...          ...        ...           ...         ...       ...   \n",
       "1053277   212662         3021     3739.0    2016-05-04  2016-05-08       4.0   \n",
       "1053278   212662         2934     5686.0    2016-03-21  2016-03-22       1.0   \n",
       "1053279   212662         3021     3739.0    2016-05-08  2016-06-02      25.0   \n",
       "1053280   752472         7113     1633.0    2016-06-13         NaN       NaN   \n",
       "1053281   752472         3621     2705.0    2016-05-23         NaN       NaN   \n",
       "\n",
       "         target Month_received   data  \n",
       "0           0.0     2016-05-01  Train  \n",
       "1           0.0     2016-02-01  Train  \n",
       "2           0.0     2016-03-01  Train  \n",
       "3           0.0     2016-06-01  Train  \n",
       "4          -1.0     2016-05-01  Train  \n",
       "...         ...            ...    ...  \n",
       "1053277     1.0     2016-05-01  Train  \n",
       "1053278     1.0     2016-03-01  Train  \n",
       "1053279    -1.0     2016-05-01  Train  \n",
       "1053280     0.0     2016-06-01  Train  \n",
       "1053281     0.0     2016-05-01  Train  \n",
       "\n",
       "[1053282 rows x 9 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target_merged[df_target_merged.data == 'Train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "valuable-ladder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast_categorical_variable(df):\n",
    "    cate_feat = list(\n",
    "    filter(lambda x: 'MODE' in x , \n",
    "           df.columns)\n",
    "    )\n",
    "    df[cate_feat] = df[cate_feat].astype(object)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "informed-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_feature = cast_categorical_variable(df_user_feature)\n",
    "df_merchant_feature = cast_categorical_variable(df_merchant_feature)\n",
    "df_coupon_feature = cast_categorical_variable(df_coupon_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "nuclear-light",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_target = df_target_merged[(df_target_merged['data'] == 'Train') & \n",
    "                                  (df_target_merged['target'] >= 0)][['User_id', 'Merchant_id',\n",
    "                                     'Coupon_id', 'datediff','target','Month_received']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "opened-hudson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Merchant_id</th>\n",
       "      <th>Coupon_id</th>\n",
       "      <th>datediff</th>\n",
       "      <th>target</th>\n",
       "      <th>Month_received</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1439408</td>\n",
       "      <td>4663</td>\n",
       "      <td>11002.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1832624</td>\n",
       "      <td>3381</td>\n",
       "      <td>7610.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053276</th>\n",
       "      <td>212662</td>\n",
       "      <td>3532</td>\n",
       "      <td>5267.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053277</th>\n",
       "      <td>212662</td>\n",
       "      <td>3021</td>\n",
       "      <td>3739.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053278</th>\n",
       "      <td>212662</td>\n",
       "      <td>2934</td>\n",
       "      <td>5686.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053280</th>\n",
       "      <td>752472</td>\n",
       "      <td>7113</td>\n",
       "      <td>1633.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053281</th>\n",
       "      <td>752472</td>\n",
       "      <td>3621</td>\n",
       "      <td>2705.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-05-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1042295 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         User_id  Merchant_id  Coupon_id  datediff  target Month_received\n",
       "0        1439408         4663    11002.0       NaN     0.0     2016-05-01\n",
       "1        1439408         2632     8591.0       NaN     0.0     2016-02-01\n",
       "2        1439408         2632     1078.0       NaN     0.0     2016-03-01\n",
       "3        1439408         2632     8591.0       NaN     0.0     2016-06-01\n",
       "5        1832624         3381     7610.0       NaN     0.0     2016-04-01\n",
       "...          ...          ...        ...       ...     ...            ...\n",
       "1053276   212662         3532     5267.0       NaN     0.0     2016-03-01\n",
       "1053277   212662         3021     3739.0       4.0     1.0     2016-05-01\n",
       "1053278   212662         2934     5686.0       1.0     1.0     2016-03-01\n",
       "1053280   752472         7113     1633.0       NaN     0.0     2016-06-01\n",
       "1053281   752472         3621     2705.0       NaN     0.0     2016-05-01\n",
       "\n",
       "[1042295 rows x 6 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-aruba",
   "metadata": {},
   "source": [
    "### statistical based feature selection\n",
    "Now, we have about 180 variables with some null values and categorical variables. In this part, we will use WoE(Weight of Evidence) transformation to save us from encoding and imputing, which is widely used in research credit risk world.\n",
    "\n",
    "blog: https://multithreaded.stitchfix.com/blog/2015/08/13/weight-of-evidence/\n",
    "\n",
    "Steps:\n",
    "1. to split (a continuous) variable into few categories or to group (a discrete) variable into few categories (and in both cases you assume that all observations in one category have \"same\" effect on dependent variable)\n",
    "2. to calculate WoE value for each category (then the original x values are replaced by the WoE values)\n",
    "\n",
    "Prons: (from the blog)\n",
    "1. Seamlessly compare the strength of continuous and categorical variables without creating dummy variables.\n",
    "2. Seamlessly handle missing values without imputation.\n",
    "3. Assess the predictive power of missing values.\n",
    "\n",
    "In this part, we use Python Package toad for WoE transformation and IV calculating.\n",
    "\n",
    "Doc: https://toad.readthedocs.io/en/stable/\n",
    "\n",
    "github: https://github.com/amphibian-dev/toad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "understanding-circle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import toad\n",
    "\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cardiovascular-classic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def woeTransform(df):\n",
    "    ### binning data use chi2 binning algorithm, the minimum threshold in each bin is 2.5%\n",
    "    ### return a combiner \n",
    "    c = toad.transform.Combiner() \n",
    "    df_binned = c.fit_transform(df, y = 'target', method = 'chi', min_samples = 0.025, n_bins=10) \n",
    "    woe_trans = toad.transform.WOETransformer()\n",
    "    df_woe = woe_trans.fit_transform(df_binned,df_binned['target'],exclude=['target'])\n",
    "    return c,woe_trans, df_woe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "valid-envelope",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user = df_train_target.merge(right=df_user_feature, how='left', \n",
    "                                left_on= ['User_id','Month_received'],\n",
    "                               right_on=['user_User_id','user_time'],\n",
    "                                )\n",
    "df_merchant_user = df_user.merge(right=df_merchant_feature, how='left',\n",
    "                                left_on=['Merchant_id','Month_received'],\n",
    "                               right_on=['merchant_Merchant_id','merchant_time'],\n",
    "                                )\n",
    "df_total = df_merchant_user.merge(right=df_coupon_feature, how='left',\n",
    "                                left_on=['Coupon_id','Month_received'],\n",
    "                               right_on=['coupon_Coupon_id','coupon_time'],\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "opposed-spain",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_user\n",
    "del df_merchant_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "reported-texture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Merchant_id</th>\n",
       "      <th>Coupon_id</th>\n",
       "      <th>datediff</th>\n",
       "      <th>target</th>\n",
       "      <th>Month_received</th>\n",
       "      <th>user_User_id</th>\n",
       "      <th>user_time</th>\n",
       "      <th>user_AVG_TIME_BETWEEN(offline.Date, unit=days)</th>\n",
       "      <th>user_AVG_TIME_BETWEEN(offline.Date_received, unit=days)</th>\n",
       "      <th>...</th>\n",
       "      <th>coupon_NUM_UNIQUE(offline.WEEKDAY(Date))</th>\n",
       "      <th>coupon_NUM_UNIQUE(offline.WEEKDAY(Date_received))</th>\n",
       "      <th>coupon_NUM_UNIQUE(offline.WEEKDAY(Date_received) WHERE use_coupon = 1)</th>\n",
       "      <th>coupon_SUM(offline.Distance WHERE use_coupon = 1)</th>\n",
       "      <th>coupon_SUM(offline.Distance WHERE discount_type = 0.0)</th>\n",
       "      <th>coupon_SUM(offline.datediff WHERE discount_type = 0.0)</th>\n",
       "      <th>coupon_SUM(offline.promotion_amonut WHERE use_coupon = 1)</th>\n",
       "      <th>coupon_SUM(offline.promotion_condition WHERE use_coupon = 1)</th>\n",
       "      <th>coupon_SUM(offline.purchase WHERE discount_type = 1.0)</th>\n",
       "      <th>coupon_SUM(offline.purchase WHERE discount_type = 0.0)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1439408</td>\n",
       "      <td>4663</td>\n",
       "      <td>11002.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>1439408.0</td>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-06-01</td>\n",
       "      <td>1439408.0</td>\n",
       "      <td>2016-06-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1832624</td>\n",
       "      <td>3381</td>\n",
       "      <td>7610.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>1832624.0</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042290</th>\n",
       "      <td>212662</td>\n",
       "      <td>3532</td>\n",
       "      <td>5267.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042291</th>\n",
       "      <td>212662</td>\n",
       "      <td>3021</td>\n",
       "      <td>3739.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>212662.0</td>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042292</th>\n",
       "      <td>212662</td>\n",
       "      <td>2934</td>\n",
       "      <td>5686.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042293</th>\n",
       "      <td>752472</td>\n",
       "      <td>7113</td>\n",
       "      <td>1633.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-06-01</td>\n",
       "      <td>752472.0</td>\n",
       "      <td>2016-06-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042294</th>\n",
       "      <td>752472</td>\n",
       "      <td>3621</td>\n",
       "      <td>2705.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>752472.0</td>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1042295 rows × 184 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         User_id  Merchant_id  Coupon_id  datediff  target Month_received  \\\n",
       "0        1439408         4663    11002.0       NaN     0.0     2016-05-01   \n",
       "1        1439408         2632     8591.0       NaN     0.0     2016-02-01   \n",
       "2        1439408         2632     1078.0       NaN     0.0     2016-03-01   \n",
       "3        1439408         2632     8591.0       NaN     0.0     2016-06-01   \n",
       "4        1832624         3381     7610.0       NaN     0.0     2016-04-01   \n",
       "...          ...          ...        ...       ...     ...            ...   \n",
       "1042290   212662         3532     5267.0       NaN     0.0     2016-03-01   \n",
       "1042291   212662         3021     3739.0       4.0     1.0     2016-05-01   \n",
       "1042292   212662         2934     5686.0       1.0     1.0     2016-03-01   \n",
       "1042293   752472         7113     1633.0       NaN     0.0     2016-06-01   \n",
       "1042294   752472         3621     2705.0       NaN     0.0     2016-05-01   \n",
       "\n",
       "         user_User_id   user_time  \\\n",
       "0           1439408.0  2016-05-01   \n",
       "1                 NaN         NaN   \n",
       "2                 NaN         NaN   \n",
       "3           1439408.0  2016-06-01   \n",
       "4           1832624.0  2016-04-01   \n",
       "...               ...         ...   \n",
       "1042290           NaN         NaN   \n",
       "1042291      212662.0  2016-05-01   \n",
       "1042292           NaN         NaN   \n",
       "1042293      752472.0  2016-06-01   \n",
       "1042294      752472.0  2016-05-01   \n",
       "\n",
       "         user_AVG_TIME_BETWEEN(offline.Date, unit=days)  \\\n",
       "0                                                   NaN   \n",
       "1                                                   NaN   \n",
       "2                                                   NaN   \n",
       "3                                                   NaN   \n",
       "4                                                   NaN   \n",
       "...                                                 ...   \n",
       "1042290                                             NaN   \n",
       "1042291                                             5.5   \n",
       "1042292                                             NaN   \n",
       "1042293                                             NaN   \n",
       "1042294                                             NaN   \n",
       "\n",
       "         user_AVG_TIME_BETWEEN(offline.Date_received, unit=days)  ...  \\\n",
       "0                                                     31.0        ...   \n",
       "1                                                      NaN        ...   \n",
       "2                                                      NaN        ...   \n",
       "3                                                     70.0        ...   \n",
       "4                                                      NaN        ...   \n",
       "...                                                    ...        ...   \n",
       "1042290                                                NaN        ...   \n",
       "1042291                                                0.5        ...   \n",
       "1042292                                                NaN        ...   \n",
       "1042293                                                NaN        ...   \n",
       "1042294                                                NaN        ...   \n",
       "\n",
       "         coupon_NUM_UNIQUE(offline.WEEKDAY(Date))  \\\n",
       "0                                             NaN   \n",
       "1                                             NaN   \n",
       "2                                             NaN   \n",
       "3                                             2.0   \n",
       "4                                             4.0   \n",
       "...                                           ...   \n",
       "1042290                                       NaN   \n",
       "1042291                                       NaN   \n",
       "1042292                                       NaN   \n",
       "1042293                                       NaN   \n",
       "1042294                                       NaN   \n",
       "\n",
       "         coupon_NUM_UNIQUE(offline.WEEKDAY(Date_received))  \\\n",
       "0                                                      NaN   \n",
       "1                                                      NaN   \n",
       "2                                                      NaN   \n",
       "3                                                      7.0   \n",
       "4                                                      6.0   \n",
       "...                                                    ...   \n",
       "1042290                                                NaN   \n",
       "1042291                                                NaN   \n",
       "1042292                                                NaN   \n",
       "1042293                                                NaN   \n",
       "1042294                                                NaN   \n",
       "\n",
       "         coupon_NUM_UNIQUE(offline.WEEKDAY(Date_received) WHERE use_coupon = 1)  \\\n",
       "0                                                      NaN                        \n",
       "1                                                      NaN                        \n",
       "2                                                      NaN                        \n",
       "3                                                      3.0                        \n",
       "4                                                      4.0                        \n",
       "...                                                    ...                        \n",
       "1042290                                                NaN                        \n",
       "1042291                                                NaN                        \n",
       "1042292                                                NaN                        \n",
       "1042293                                                NaN                        \n",
       "1042294                                                NaN                        \n",
       "\n",
       "         coupon_SUM(offline.Distance WHERE use_coupon = 1)  \\\n",
       "0                                                      0.0   \n",
       "1                                                      NaN   \n",
       "2                                                      NaN   \n",
       "3                                                      3.0   \n",
       "4                                                      2.0   \n",
       "...                                                    ...   \n",
       "1042290                                                NaN   \n",
       "1042291                                                0.0   \n",
       "1042292                                                NaN   \n",
       "1042293                                                0.0   \n",
       "1042294                                                0.0   \n",
       "\n",
       "         coupon_SUM(offline.Distance WHERE discount_type = 0.0)  \\\n",
       "0                                                      0.0        \n",
       "1                                                      NaN        \n",
       "2                                                      NaN        \n",
       "3                                                      0.0        \n",
       "4                                                      0.0        \n",
       "...                                                    ...        \n",
       "1042290                                                NaN        \n",
       "1042291                                                0.0        \n",
       "1042292                                                NaN        \n",
       "1042293                                                0.0        \n",
       "1042294                                                0.0        \n",
       "\n",
       "         coupon_SUM(offline.datediff WHERE discount_type = 0.0)  \\\n",
       "0                                                      0.0        \n",
       "1                                                      NaN        \n",
       "2                                                      NaN        \n",
       "3                                                      0.0        \n",
       "4                                                      0.0        \n",
       "...                                                    ...        \n",
       "1042290                                                NaN        \n",
       "1042291                                                0.0        \n",
       "1042292                                                NaN        \n",
       "1042293                                                0.0        \n",
       "1042294                                                0.0        \n",
       "\n",
       "         coupon_SUM(offline.promotion_amonut WHERE use_coupon = 1)  \\\n",
       "0                                                      0.0           \n",
       "1                                                      NaN           \n",
       "2                                                      NaN           \n",
       "3                                                      3.0           \n",
       "4                                                    160.0           \n",
       "...                                                    ...           \n",
       "1042290                                                NaN           \n",
       "1042291                                                0.0           \n",
       "1042292                                                NaN           \n",
       "1042293                                                0.0           \n",
       "1042294                                                0.0           \n",
       "\n",
       "         coupon_SUM(offline.promotion_condition WHERE use_coupon = 1)  \\\n",
       "0                                                      0.0              \n",
       "1                                                      NaN              \n",
       "2                                                      NaN              \n",
       "3                                                     60.0              \n",
       "4                                                   1600.0              \n",
       "...                                                    ...              \n",
       "1042290                                                NaN              \n",
       "1042291                                                0.0              \n",
       "1042292                                                NaN              \n",
       "1042293                                                0.0              \n",
       "1042294                                                0.0              \n",
       "\n",
       "         coupon_SUM(offline.purchase WHERE discount_type = 1.0)  \\\n",
       "0                                                      0.0        \n",
       "1                                                      NaN        \n",
       "2                                                      NaN        \n",
       "3                                                      3.0        \n",
       "4                                                      8.0        \n",
       "...                                                    ...        \n",
       "1042290                                                NaN        \n",
       "1042291                                                0.0        \n",
       "1042292                                                NaN        \n",
       "1042293                                                0.0        \n",
       "1042294                                                0.0        \n",
       "\n",
       "         coupon_SUM(offline.purchase WHERE discount_type = 0.0)  \n",
       "0                                                      0.0       \n",
       "1                                                      NaN       \n",
       "2                                                      NaN       \n",
       "3                                                      0.0       \n",
       "4                                                      0.0       \n",
       "...                                                    ...       \n",
       "1042290                                                NaN       \n",
       "1042291                                                0.0       \n",
       "1042292                                                NaN       \n",
       "1042293                                                0.0       \n",
       "1042294                                                0.0       \n",
       "\n",
       "[1042295 rows x 184 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fatal-fellowship",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1042295, 6)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "sitting-roberts",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = list(df_user_feature.columns)[2:]+list(df_merchant_feature.columns)[2:]+list(df_coupon_feature.columns)[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "geographic-porcelain",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_woe = df_total[features_list + ['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "peripheral-watershed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'empty': array(['user_MEAN(online.uniform_discount_rate)',\n",
      "       'user_MODE(online.Discount_rate WHERE Action = 2)',\n",
      "       'user_NUM_UNIQUE(online.Merchant_id WHERE Action = 2)',\n",
      "       'user_NUM_UNIQUE(online.WEEKDAY(Date_received) WHERE Action = 2)'],\n",
      "      dtype='<U63'), 'iv': array(['user_MEAN(online.promotion_amonut)',\n",
      "       'user_MEAN(online.promotion_condition)',\n",
      "       'user_MODE(online.Discount_rate)',\n",
      "       'user_MEAN(online.use_coupon WHERE Action = 1)',\n",
      "       'user_MODE(online.WEEKDAY(Date) WHERE Action = 1)',\n",
      "       'user_MODE(online.WEEKDAY(Date_received))',\n",
      "       'user_NUM_UNIQUE(online.Coupon_id WHERE Action = 1)',\n",
      "       'user_NUM_UNIQUE(online.Merchant_id WHERE Action = 1)',\n",
      "       'user_NUM_UNIQUE(online.WEEKDAY(Date) WHERE Action = 1)',\n",
      "       'user_NUM_UNIQUE(online.WEEKDAY(Date_received) WHERE Action = 1)',\n",
      "       'merchant_MIN(merchant_offline.Distance WHERE discount_type = 1.0)'],\n",
      "      dtype=object), 'corr': array(['merchant_SUM(merchant_offline.Distance WHERE purchase = 1)',\n",
      "       'merchant_SUM(merchant_offline.promotion_amonut)',\n",
      "       'merchant_SUM(merchant_offline.datediff)',\n",
      "       'merchant_COUNT(merchant_offline)',\n",
      "       'merchant_SUM(merchant_offline.Distance WHERE use_coupon = 1)',\n",
      "       'coupon_SUM(offline.Distance WHERE discount_type = 0.0)',\n",
      "       'merchant_NUM_UNIQUE(merchant_offline.WEEKDAY(Date_received) WHERE discount_type = 0.0)',\n",
      "       'coupon_SUM(offline.purchase WHERE discount_type = 0.0)',\n",
      "       'user_MEAN(offline.promotion_condition)',\n",
      "       'coupon_MAX(offline.promotion_condition)',\n",
      "       'coupon_SUM(offline.Distance)',\n",
      "       'user_NUM_UNIQUE(online.Coupon_id)',\n",
      "       'user_SUM(offline.datediff WHERE discount_type = 0.0)',\n",
      "       'user_NUM_UNIQUE(offline.Merchant_id WHERE discount_type = 1.0)',\n",
      "       'user_MIN(offline.promotion_amonut)',\n",
      "       'user_MEAN(offline.uniform_discount_rate)',\n",
      "       'user_MAX(offline.promotion_amonut)',\n",
      "       'user_MEAN(offline.Distance)',\n",
      "       'merchant_SUM(merchant_offline.Distance WHERE discount_type = 0.0)',\n",
      "       'coupon_COUNT(offline)', 'coupon_MIN(offline.purchase)',\n",
      "       'coupon_MIN(offline.datediff)',\n",
      "       'merchant_MAX(merchant_offline.Distance WHERE discount_type = 1.0)',\n",
      "       'user_SUM(offline.Distance)',\n",
      "       'coupon_SUM(offline.datediff WHERE discount_type = 0.0)',\n",
      "       'user_COUNT(offline WHERE discount_type = 0.0)',\n",
      "       'merchant_NUM_UNIQUE(merchant_offline.Discount_rate WHERE use_coupon = 1)',\n",
      "       'merchant_MAX(merchant_offline.uniform_discount_rate)',\n",
      "       'coupon_NUM_UNIQUE(offline.WEEKDAY(Date))',\n",
      "       'coupon_MAX(offline.datediff)',\n",
      "       'coupon_MEAN(offline.Distance WHERE use_coupon = 1)',\n",
      "       'coupon_NUM_UNIQUE(offline.User_id WHERE use_coupon = 1)',\n",
      "       'coupon_SUM(offline.promotion_amonut WHERE use_coupon = 1)',\n",
      "       'merchant_MAX(merchant_offline.datediff)',\n",
      "       'merchant_COUNT(merchant_offline WHERE discount_type = 0.0)',\n",
      "       'user_MEAN(offline.purchase WHERE discount_type = 1.0)',\n",
      "       'user_NUM_UNIQUE(offline.WEEKDAY(Date) WHERE discount_type = 1.0)',\n",
      "       'coupon_MAX(offline.promotion_amonut)',\n",
      "       'coupon_SUM(offline.datediff)',\n",
      "       'coupon_SUM(offline.promotion_amonut)',\n",
      "       'merchant_SUM(merchant_offline.use_coupon)'], dtype=object)}\n",
      "(1042295, 117)\n"
     ]
    }
   ],
   "source": [
    "#Conduct preliminary feature selection according to missing percentage, IV and correlation (with other features)\n",
    "train_selected, dropped = toad.selection.select(df_woe,target = 'target',\n",
    "                                                empty = 0.95, iv = 0.01, corr = 0.8,\n",
    "                                                return_drop=True)\n",
    "print(dropped)\n",
    "print(train_selected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-mailman",
   "metadata": {},
   "outputs": [],
   "source": [
    "combiner,woe_transformer,transformed = woeTransform(train_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-moore",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-generation",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed.to_csv('./dataset/woe_feature_train.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impaired-nepal",
   "metadata": {},
   "source": [
    "### MODEL based selection\n",
    "\n",
    "Use Transformed feature for LogisticRegression, Random Forest, XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "secure-blanket",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = transformed.drop('target',axis=1)\n",
    "y = transformed['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state = 1024,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "minimal-security",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(729606, 116)\n",
      "(312689, 116)\n",
      "Positive rate in train set:6.19%\n",
      "Positive rate in validation set:6.15%\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print('Positive rate in train set:{:.2%}'.format(y_train.mean()))\n",
    "print('Positive rate in validation set:{:.2%}'.format(y_test.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eight-criticism",
   "metadata": {},
   "source": [
    "#### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "floral-conjunction",
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = SelectFromModel(estimator=\n",
    "                           LogisticRegression(solver='lbfgs',class_weight='balanced', max_iter=5000)\n",
    "                          ,threshold='mean').fit(\n",
    "    StandardScaler().fit_transform(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "reliable-binary",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_features = set(X_train.columns[selector.get_support()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "invisible-details",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lr_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floating-wheel",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "starting-austin",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=200, verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "curious-death",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   18.9s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=200, n_jobs=-1, verbose=1)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "oriented-brain",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_features = set(X_train.columns[rf.feature_importances_ > np.mean(rf.feature_importances_)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "double-suspect",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rf_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "large-therapy",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "unknown-payday",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(n_estimators=200, max_depth=3,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "offshore-carroll",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/billy/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:56:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=200, n_jobs=-1, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "welcome-chamber",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_features = set(X_train.columns[xgb.feature_importances_ >  np.mean(xgb.feature_importances_)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "placed-dayton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lr_features.union(rf_features.union(xgb_features))).difference(set(features_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ideal-secret",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_features = list(lr_features.union(rf_features.union(xgb_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "unusual-shelf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "selected_count = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "tamil-respect",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in lr_features:\n",
    "    selected_count[f]+=1\n",
    "for f in rf_features:\n",
    "    selected_count[f]+=1\n",
    "for f in xgb_features:\n",
    "    selected_count[f]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "attended-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target_total = df_target_merged[['User_id', 'Merchant_id',\n",
    "                                     'Coupon_id', 'datediff','target','Month_received','data']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "american-biography",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Merchant_id</th>\n",
       "      <th>Coupon_id</th>\n",
       "      <th>datediff</th>\n",
       "      <th>target</th>\n",
       "      <th>Month_received</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1439408</td>\n",
       "      <td>4663</td>\n",
       "      <td>11002.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-03-01</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-06-01</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166917</th>\n",
       "      <td>5828093</td>\n",
       "      <td>5717</td>\n",
       "      <td>10418.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166918</th>\n",
       "      <td>6626813</td>\n",
       "      <td>1699</td>\n",
       "      <td>7595.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166919</th>\n",
       "      <td>6626813</td>\n",
       "      <td>7321</td>\n",
       "      <td>7590.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166920</th>\n",
       "      <td>4547069</td>\n",
       "      <td>760</td>\n",
       "      <td>13602.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166921</th>\n",
       "      <td>6675965</td>\n",
       "      <td>7487</td>\n",
       "      <td>613.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1166922 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         User_id  Merchant_id  Coupon_id  datediff  target Month_received  \\\n",
       "0        1439408         4663    11002.0       NaN     0.0     2016-05-01   \n",
       "1        1439408         2632     8591.0       NaN     0.0     2016-02-01   \n",
       "2        1439408         2632     1078.0       NaN     0.0     2016-03-01   \n",
       "3        1439408         2632     8591.0       NaN     0.0     2016-06-01   \n",
       "4        1439408         2632     8591.0      28.0    -1.0     2016-05-01   \n",
       "...          ...          ...        ...       ...     ...            ...   \n",
       "1166917  5828093         5717    10418.0       NaN     NaN     2016-07-01   \n",
       "1166918  6626813         1699     7595.0       NaN     NaN     2016-07-01   \n",
       "1166919  6626813         7321     7590.0       NaN     NaN     2016-07-01   \n",
       "1166920  4547069          760    13602.0       NaN     NaN     2016-07-01   \n",
       "1166921  6675965         7487      613.0       NaN     NaN     2016-07-01   \n",
       "\n",
       "          data  \n",
       "0        Train  \n",
       "1        Train  \n",
       "2        Train  \n",
       "3        Train  \n",
       "4        Train  \n",
       "...        ...  \n",
       "1166917   Test  \n",
       "1166918   Test  \n",
       "1166919   Test  \n",
       "1166920   Test  \n",
       "1166921   Test  \n",
       "\n",
       "[1166922 rows x 7 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "assisted-proxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user = df_target_total.merge(right=df_user_feature, how='left', \n",
    "                                left_on= ['User_id','Month_received'],\n",
    "                               right_on=['user_User_id','user_time'],\n",
    "                                )\n",
    "df_merchant_user = df_user.merge(right=df_merchant_feature, how='left',\n",
    "                                left_on=['Merchant_id','Month_received'],\n",
    "                               right_on=['merchant_Merchant_id','merchant_time'],\n",
    "                                )\n",
    "df_total = df_merchant_user.merge(right=df_coupon_feature, how='left',\n",
    "                                left_on=['Coupon_id','Month_received'],\n",
    "                               right_on=['coupon_Coupon_id','coupon_time'],\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "material-black",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_selected = df_total[['User_id', 'Merchant_id','Coupon_id', \n",
    "                                'datediff','target','Month_received','data'] \n",
    "                               + result_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "executive-number",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_selected.to_csv('feature_selected_train&test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environmental-blogger",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_total_woe = woe_transformer.transform(df_total[features_list])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
