{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "consolidated-theme",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "incorporated-hydrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import time as time_m\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.pipeline import  FeatureUnion #Pipeline,\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler \n",
    "# from sklearn.externals import joblib\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "absent-annotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset/feature_selected_train&test.csv')\n",
    "cate = pd.read_csv('dataset/feature_selected_train&test_cate_woe.csv')\n",
    "kmeans = pd.read_csv('dataset/kmeans_label.csv')[['User_id','kmeans_group','time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "corresponding-garlic",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = cate.columns\n",
    "data[cols] = cate[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "varied-horizontal",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = []\n",
    "with open('dataset/feature_names.txt') as f:\n",
    "    for line in f.readlines():\n",
    "        cols.append(line.strip()) \n",
    "# print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aware-terminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.merge(data,kmeans,left_on=['User_id','Month_received'],right_on=['User_id','time'], how='left')\n",
    "data= data.drop(['time'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "whole-beast",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          2016-05-01\n",
       "1                 NaN\n",
       "2                 NaN\n",
       "3          2016-06-01\n",
       "4          2016-05-01\n",
       "              ...    \n",
       "1166917    2016-07-01\n",
       "1166918    2016-07-01\n",
       "1166919    2016-07-01\n",
       "1166920    2016-07-01\n",
       "1166921    2016-07-01\n",
       "Name: time, Length: 1166922, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-settle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "elementary-collectible",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[(data['data']=='Train') & (data['target'] != -1)]\n",
    "test = data[(data['data']=='Test') & (data['target'] != -1)]\n",
    "train = train.drop('data',axis=1)\n",
    "test = test.drop('data',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "confidential-infrastructure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1522"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del data, cate, kmeans\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "enabling-plenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train[cols]\n",
    "test_x = test[cols]\n",
    "# columns_to_drop = list(train_x.columns[:6])\n",
    "# train_x = train_x.drop(columns_to_drop,axis = 1)\n",
    "# test_x = test_x.drop(columns_to_drop, axis = 1)\n",
    "train_y = train.target.astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "numerical-bruce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,test_x,train_y,test_y = train_test_split(train_x,train_y, test_size=0.3,random_state=5,stratify=train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "equipped-seven",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(847315, 85)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "sapphire-chuck",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    792103\n",
       "1     55212\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "explicit-fireplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "test_x = test_x.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "swedish-reunion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train,test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "light-sampling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm = SVC(probability=True) #class_weight=svmweight, C=svmc, kernel=svmkernel, \n",
    "rf = RandomForestClassifier(random_state=114514)\n",
    "lr = LogisticRegression(solver = 'saga',random_state =114514)\n",
    "xgb = XGBClassifier(booster='gbtree',gamma=1,seed=114514)\n",
    "smote = SMOTE(random_state=114514)\n",
    "ros = RandomOverSampler(sampling_strategy = 0.7,random_state=114514)\n",
    "lgb = LGBMClassifier(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "clean-professor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_param_grid(clr):\n",
    "    if clr == 'lgb':\n",
    "        param_grid = dict(\n",
    "            classifier__metric = ['auc', 'binary_logloss'],\n",
    "            classifier__num_iterations=[50,100,150],\n",
    "            classifier__seed = [114514],\n",
    "            classifier__max_depth = [10, 20],\n",
    "            classifier__objective = ['binary'],\n",
    "            upsample__sampling_strategy = [0.1,0.7],\n",
    "            classifier__num_leaves = [15,35] #be smaller than 2^(max_depth)\n",
    "        )\n",
    "    elif clr == 'rf':\n",
    "        param_grid = dict(\n",
    "            classifier__n_estimators = [10,15],\n",
    "            upsample__sampling_strategy = [0.1,0.7]\n",
    "        )\n",
    "    elif clr == 'lr':\n",
    "        param_grid = dict(\n",
    "            classifier__penalty = ['none','l1','l2'],\n",
    "            classifier__class_weight = ['balanced'],\n",
    "            upsample__sampling_strategy = [0.1,0.7]\n",
    "        )\n",
    "    elif clr == 'xgb':\n",
    "        param_grid = dict(\n",
    "            classifier__n_estimators=[50,100,150],\n",
    "            classifier__learning_rate=[0.1],\n",
    "            classifier__max_depth=[5, 10, 20],\n",
    "            classifier__tree_method = ['hist'],\n",
    "            classifier__eval_metric = ['auc', 'binary_logloss'],\n",
    "            classifier__seed = [0],\n",
    "            upsample__sampling_strategy = [0.1,0.7]\n",
    "        )\n",
    "    return param_grid\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "tracked-animal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "Classifier: ['lgb']\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "Classifier: ['lr']\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "Classifier: ['rf']\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Performing grid search...\n",
      "Classifier: ['xgb']\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.76145407 0.76364496 0.76690046 0.76854352 0.76960654 0.77112976\n",
      " 0.7783791  0.77896256 0.78221739 0.78027044 0.78393788 0.78000769\n",
      " 0.7849263  0.76028929 0.78078002 0.75324018 0.77879416 0.75154119\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "param_grid = 0\n",
    "models = []\n",
    "for classifier in zip([lgb,lr,rf,xgb],['lgb','lr','rf','xgb']):\n",
    "# for classifier in zip([lgb],['lgb']):\n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"Classifier:\", [classifier[1]])\n",
    "    param_grid = get_param_grid(classifier[1])\n",
    "    pipeline = Pipeline([('upsample',ros),('classifier',classifier[0])])\n",
    "    grid_search = GridSearchCV(pipeline, param_grid=param_grid, verbose=10, n_jobs=6,scoring='roc_auc')\n",
    "    if classifier[0] == xgb:\n",
    "        grid_search.fit(train_x, train_y)\n",
    "    else:\n",
    "        cache = train_x.fillna(0)\n",
    "        grid_search.fit(cache, train_y)\n",
    "        del cache\n",
    "        gc.collect()\n",
    "    models.append((grid_search.best_score_,grid_search.best_estimator_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bronze-unemployment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.7740519248829528,\n",
       "  Pipeline(steps=[('upsample',\n",
       "                   RandomOverSampler(random_state=114514, sampling_strategy=0.7)),\n",
       "                  ('classifier',\n",
       "                   LGBMClassifier(max_depth=10, metric='auc', num_iterations=150,\n",
       "                                  num_leaves=35, objective='binary',\n",
       "                                  seed=114514))])),\n",
       " (0.6204357542571204,\n",
       "  Pipeline(steps=[('upsample',\n",
       "                   RandomOverSampler(random_state=114514, sampling_strategy=0.7)),\n",
       "                  ('classifier',\n",
       "                   LogisticRegression(class_weight='balanced',\n",
       "                                      random_state=114514, solver='saga'))])),\n",
       " (0.7699390422738324,\n",
       "  Pipeline(steps=[('upsample',\n",
       "                   RandomOverSampler(random_state=114514, sampling_strategy=0.1)),\n",
       "                  ('classifier',\n",
       "                   RandomForestClassifier(n_estimators=15, random_state=114514))])),\n",
       " (0.7849262995417513,\n",
       "  Pipeline(steps=[('upsample',\n",
       "                   RandomOverSampler(random_state=114514, sampling_strategy=0.1)),\n",
       "                  ('classifier',\n",
       "                   XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                 colsample_bylevel=1, colsample_bynode=1,\n",
       "                                 colsample_bytree=1, eval_metric='auc', gamma=1,\n",
       "                                 gpu_id=-1, importance_type='gain',\n",
       "                                 interaction_constraints='', learning_rate=0.1,\n",
       "                                 max_delta_step=0, max_depth=20,\n",
       "                                 min_child_weight=1, missing=nan,\n",
       "                                 monotone_constraints='()', n_estimators=50,\n",
       "                                 n_jobs=12, num_parallel_tree=1, random_state=0,\n",
       "                                 reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                                 seed=0, subsample=1, tree_method='hist',\n",
       "                                 validate_parameters=1, verbosity=None))]))]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "interested-enterprise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('upsample',\n",
       "                                        RandomOverSampler(random_state=114514,\n",
       "                                                          sampling_strategy=0.7)),\n",
       "                                       ('classifier',\n",
       "                                        XGBClassifier(base_score=None,\n",
       "                                                      booster='gbtree',\n",
       "                                                      colsample_bylevel=None,\n",
       "                                                      colsample_bynode=None,\n",
       "                                                      colsample_bytree=None,\n",
       "                                                      gamma=1, gpu_id=None,\n",
       "                                                      importance_type='gain',\n",
       "                                                      interaction_constraints=None,\n",
       "                                                      learning_rate=None,\n",
       "                                                      max_delta_step=Non...\n",
       "                                                      validate_parameters=None,\n",
       "                                                      verbosity=None))]),\n",
       "             n_jobs=6,\n",
       "             param_grid={'classifier__eval_metric': ['auc', 'binary_logloss'],\n",
       "                         'classifier__learning_rate': [0.1],\n",
       "                         'classifier__max_depth': [5, 10, 20],\n",
       "                         'classifier__n_estimators': [50, 100, 150],\n",
       "                         'classifier__seed': [0],\n",
       "                         'classifier__tree_method': ['hist'],\n",
       "                         'upsample__sampling_strategy': [0.1, 0.7]},\n",
       "             scoring='roc_auc', verbose=10)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "federal-witness",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predict(models, train_x, train_y, test_x):\n",
    "    total_score = sum([i[0] for i in models])\n",
    "    res = []\n",
    "    for i in models:\n",
    "        if 'xgb' in str(i[1]):\n",
    "            print('1',i[1])\n",
    "            i[1].fit(train_x, train_y)\n",
    "            y = i[1].predict_proba(test_x)\n",
    "            print(y)\n",
    "            y = y*i[0]/total_score\n",
    "            res.append(y)\n",
    "        else:\n",
    "            print('2' , i[1])\n",
    "            cache = train_x.fillna(0)\n",
    "            i[1].fit(cache, train_y)\n",
    "            cache = test_x.fillna(0)\n",
    "            y = i[1].predict_proba(cache)\n",
    "            print(y)\n",
    "            y = y*i[0]/total_score\n",
    "            res.append(y)\n",
    "            del cache\n",
    "            gc.collect()\n",
    "        print(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "varying-kingston",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Pipeline(steps=[('upsample',\n",
      "                 RandomOverSampler(random_state=114514, sampling_strategy=0.7)),\n",
      "                ('classifier',\n",
      "                 LGBMClassifier(max_depth=10, metric='auc', num_iterations=150,\n",
      "                                num_leaves=35, objective='binary',\n",
      "                                seed=114514))])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6539372  0.3460628 ]\n",
      " [0.6539372  0.3460628 ]\n",
      " [0.6539372  0.3460628 ]\n",
      " ...\n",
      " [0.52695281 0.47304719]\n",
      " [0.6539372  0.3460628 ]\n",
      " [0.68324023 0.31675977]]\n",
      "[array([[0.17162454, 0.0908235 ],\n",
      "       [0.17162454, 0.0908235 ],\n",
      "       [0.17162454, 0.0908235 ],\n",
      "       ...,\n",
      "       [0.13829773, 0.12415031],\n",
      "       [0.17162454, 0.0908235 ],\n",
      "       [0.17931506, 0.08313298]])]\n",
      "2 Pipeline(steps=[('upsample',\n",
      "                 RandomOverSampler(random_state=114514, sampling_strategy=0.7)),\n",
      "                ('classifier',\n",
      "                 LogisticRegression(class_weight='balanced',\n",
      "                                    random_state=114514, solver='saga'))])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.50000006 0.49999994]\n",
      " [0.50000006 0.49999994]\n",
      " [0.50000006 0.49999994]\n",
      " ...\n",
      " [0.50224658 0.49775342]\n",
      " [0.50000006 0.49999994]\n",
      " [0.35415349 0.64584651]]\n",
      "[array([[0.17162454, 0.0908235 ],\n",
      "       [0.17162454, 0.0908235 ],\n",
      "       [0.17162454, 0.0908235 ],\n",
      "       ...,\n",
      "       [0.13829773, 0.12415031],\n",
      "       [0.17162454, 0.0908235 ],\n",
      "       [0.17931506, 0.08313298]]), array([[0.10518168, 0.10518166],\n",
      "       [0.10518168, 0.10518166],\n",
      "       [0.10518168, 0.10518166],\n",
      "       ...,\n",
      "       [0.10565427, 0.10470907],\n",
      "       [0.10518168, 0.10518166],\n",
      "       [0.07450091, 0.13586243]])]\n",
      "2 Pipeline(steps=[('upsample',\n",
      "                 RandomOverSampler(random_state=114514, sampling_strategy=0.1)),\n",
      "                ('classifier',\n",
      "                 RandomForestClassifier(n_estimators=15, random_state=114514))])\n",
      "[[0.92974728 0.07025272]\n",
      " [0.92974728 0.07025272]\n",
      " [0.92974728 0.07025272]\n",
      " ...\n",
      " [1.         0.        ]\n",
      " [0.92974728 0.07025272]\n",
      " [0.6        0.4       ]]\n",
      "[array([[0.17162454, 0.0908235 ],\n",
      "       [0.17162454, 0.0908235 ],\n",
      "       [0.17162454, 0.0908235 ],\n",
      "       ...,\n",
      "       [0.13829773, 0.12415031],\n",
      "       [0.17162454, 0.0908235 ],\n",
      "       [0.17931506, 0.08313298]]), array([[0.10518168, 0.10518166],\n",
      "       [0.10518168, 0.10518166],\n",
      "       [0.10518168, 0.10518166],\n",
      "       ...,\n",
      "       [0.10565427, 0.10470907],\n",
      "       [0.10518168, 0.10518166],\n",
      "       [0.07450091, 0.13586243]]), array([[0.24271382, 0.01833972],\n",
      "       [0.24271382, 0.01833972],\n",
      "       [0.24271382, 0.01833972],\n",
      "       ...,\n",
      "       [0.26105354, 0.        ],\n",
      "       [0.24271382, 0.01833972],\n",
      "       [0.15663212, 0.10442142]])]\n",
      "2 Pipeline(steps=[('upsample',\n",
      "                 RandomOverSampler(random_state=114514, sampling_strategy=0.1)),\n",
      "                ('classifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, eval_metric='auc', gamma=1,\n",
      "                               gpu_id=-1, importance_type='gain',\n",
      "                               interaction_constraints='', learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=20,\n",
      "                               min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=50,\n",
      "                               n_jobs=12, num_parallel_tree=1, random_state=0,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=0, subsample=1, tree_method='hist',\n",
      "                               validate_parameters=1, verbosity=None))])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.92725354 0.07274644]\n",
      " [0.92725354 0.07274644]\n",
      " [0.92725354 0.07274644]\n",
      " ...\n",
      " [0.8944893  0.10551071]\n",
      " [0.92725354 0.07274644]\n",
      " [0.96165735 0.03834264]]\n",
      "[array([[0.17162454, 0.0908235 ],\n",
      "       [0.17162454, 0.0908235 ],\n",
      "       [0.17162454, 0.0908235 ],\n",
      "       ...,\n",
      "       [0.13829773, 0.12415031],\n",
      "       [0.17162454, 0.0908235 ],\n",
      "       [0.17931506, 0.08313298]]), array([[0.10518168, 0.10518166],\n",
      "       [0.10518168, 0.10518166],\n",
      "       [0.10518168, 0.10518166],\n",
      "       ...,\n",
      "       [0.10565427, 0.10470907],\n",
      "       [0.10518168, 0.10518166],\n",
      "       [0.07450091, 0.13586243]]), array([[0.24271382, 0.01833972],\n",
      "       [0.24271382, 0.01833972],\n",
      "       [0.24271382, 0.01833972],\n",
      "       ...,\n",
      "       [0.26105354, 0.        ],\n",
      "       [0.24271382, 0.01833972],\n",
      "       [0.15663212, 0.10442142]]), array([[0.2467747 , 0.01936038],\n",
      "       [0.2467747 , 0.01936038],\n",
      "       [0.2467747 , 0.01936038],\n",
      "       ...,\n",
      "       [0.23805498, 0.0280801 ],\n",
      "       [0.2467747 , 0.01936038],\n",
      "       [0.25593075, 0.01020432]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "res = get_predict(models, train_x, train_y, test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "welsh-exploration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7740519248829528,\n",
       " 0.6204357542571204,\n",
       " 0.7699390422738324,\n",
       " 0.7849262995417513]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "([i[0] for i in models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stainless-canberra",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-complexity",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.9",
   "language": "python",
   "name": "python3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
