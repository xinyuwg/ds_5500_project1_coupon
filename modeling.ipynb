{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "arranged-bruce",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "prerequisite-berry",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import time as time_m\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.externals import joblib\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "sufficient-centre",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset/feature_selected_train&test.csv')\n",
    "cate = pd.read_csv('dataset/feature_selected_train&test_cate_woe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "weird-header",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = cate.columns\n",
    "data[cols] = cate[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "complex-meaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[(data['data']=='Train') & (data['target'] != -1)]\n",
    "test = data[(data['data']=='Test') & (data['target'] != -1)]\n",
    "train = train.drop('data',axis=1)\n",
    "test = test.drop('data',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "reserved-romance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "716"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del data, cate\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "copyrighted-bermuda",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train.drop('target',axis = 1)\n",
    "test_x = test.drop('target',axis = 1)\n",
    "train_y = train.target.astype(\"int\")\n",
    "test_y = test.target.astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aging-interim",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,test_x,train_y,test_y = train_test_split(train_x,train_y, test_size=0.3,random_state=5,stratify=train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "becoming-complaint",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.Month_received = train_x.Month_received.apply(lambda x:time_m.mktime(time_m.strptime(x,'%Y-%m-%d')))\n",
    "test_x.Month_received = test_x.Month_received.apply(lambda x:time_m.mktime(time_m.strptime(x,'%Y-%m-%d')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "signed-disposal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(729606,)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "premium-metadata",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    684530\n",
       "1     45076\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "stock-technical",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train,test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "unexpected-welcome",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(probability=True) #class_weight=svmweight, C=svmc, kernel=svmkernel, \n",
    "rf = RandomForestClassifier(random_state=114514)\n",
    "lr = LogisticRegression(solver = 'saga',random_state =114514)\n",
    "xgb = XGBClassifier(seed=114514)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "medical-audio",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_param_grid(clr):\n",
    "    if clr == 'svm':\n",
    "        param_grid = dict(\n",
    "            C = [0.5,1,2],\n",
    "            kernel=['linear', 'poly', 'rbf'],\n",
    "            gamma=[0.5,1,3,5]\n",
    "        )\n",
    "    elif clr == 'rf':\n",
    "        param_grid = dict(\n",
    "            n_estimators = [10,15]\n",
    "        )\n",
    "    elif clr == 'lr':\n",
    "        param_grid = dict(\n",
    "            penalty = ['none','l1','l2'],\n",
    "            class_weight = ['balanced']\n",
    "        )\n",
    "    elif clr == 'xgb':\n",
    "        param_grid = dict(\n",
    "            n_estimators=[50],\n",
    "            learning_rate=[0.1],\n",
    "            max_depth=[10]\n",
    "        )\n",
    "    return param_grid\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "functional-niagara",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "Classifier: ['lr']\n",
      "Parameters and HyperParameters:\n",
      "{'class_weight': ['balanced'], 'penalty': ['none', 'l1', 'l2']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wangj\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   3 out of   9 | elapsed:  1.2min remaining:  2.4min\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   9 | elapsed:  1.8min remaining:  2.2min\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   9 | elapsed:  2.5min remaining:  2.0min\n",
      "[Parallel(n_jobs=4)]: Done   6 out of   9 | elapsed:  3.0min remaining:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done   7 out of   9 | elapsed:  3.0min remaining:   51.6s\n",
      "[Parallel(n_jobs=4)]: Done   9 out of   9 | elapsed:  3.5min remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   9 out of   9 | elapsed:  3.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search done in 300.343s \n",
      "\n",
      "Best score: 0.584\n",
      "Best parameters set:\n",
      "\tclass_weight: 'balanced'\n",
      "\tpenalty: 'none'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wangj\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97    293370\n",
      "           1       0.16      0.00      0.00     19319\n",
      "\n",
      "    accuracy                           0.94    312689\n",
      "   macro avg       0.55      0.50      0.49    312689\n",
      "weighted avg       0.89      0.94      0.91    312689\n",
      "\n",
      "Confusion Matrix\n",
      "[[293250    120]\n",
      " [ 19296     23]]\n",
      "AUC\n",
      "0.5003907490166988\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for classifier in zip([svm, rf, lr, xgb],['svm', 'rf', 'lr', 'xgb']):\n",
    "for classifier in zip([lr,rf,xgb],['lr','rf','xgb']):\n",
    "    param_grid = get_param_grid(classifier[1])\n",
    "\n",
    "    # The CV indicates it does cross_validation. By default 5-fold cross validation\n",
    "    grid_search = GridSearchCV(classifier[0], param_grid=param_grid, verbose=10, n_jobs=4,scoring='roc_auc')\n",
    "\n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"Classifier:\", [classifier[1]])\n",
    "    print(\"Parameters and HyperParameters:\")\n",
    "    pprint(param_grid)\n",
    "\n",
    "    # Run for 1 classifier. I always time these, and log the time\n",
    "    t0 = time()\n",
    "    if classifier[0] == xgb:\n",
    "        grid_search.fit(train_x, train_y)\n",
    "    else:\n",
    "        cache = train_x.fillna(0)\n",
    "        grid_search.fit(cache, train_y)\n",
    "        del cache\n",
    "        gc.collect()\n",
    "    print(\"Grid search done in %0.3fs \\n\" % (time() - t0))\n",
    "\n",
    "    # Now print the score (the actual # is not important), and best param values\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(param_grid.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    # and run the predictions with the best parameters,sanity-check again\n",
    "    if classifier[0] == xgb:\n",
    "        pred_y = grid_search.predict(test_x)\n",
    "    else:\n",
    "        cache = test_x.fillna(0)\n",
    "        pred_y = grid_search.predict(cache)\n",
    "        del cache\n",
    "        gc.collect()\n",
    "\n",
    "    # Now compute metrics\n",
    "    print(\"Classification Report\")\n",
    "    print(classification_report(test_y, pred_y))\n",
    "\n",
    "    print(\"Confusion Matrix\")\n",
    "    print(confusion_matrix(test_y, pred_y))\n",
    "    \n",
    "    print(\"AUC\")\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(test_y, pred_y)\n",
    "    print(metrics.auc(fpr, tpr))\n",
    "\n",
    "    print('\\n')\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-cleanup",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-retailer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "widespread-leisure",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-provision",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
